"""
Utilities to load recorded animation data and construct basic machine learning models.

This module contains helper functions to parse the JSON output generated by
AnimationDataRecorder.cs, convert it into a format suitable for model
training, and create skeleton definitions for multi‑layer perceptron (MLP) and
convolutional neural network (CNN) models. These are provided as stubs – you
should fill in the training loops and parameter details yourself based on
your project requirements.

The expected JSON structure looks like this (indentation for clarity):

```
{
  "frames": [
    {
      "time": 0.0,
      "positions": {
        "hip": {"x": 0.0, "y": 1.0, "z": 0.0},
        "leftKnee": {"x": ...},
        ...
      }
    },
    ...
  ]
}
```

Each frame entry contains a timestamp and a dictionary of joint positions. The
loader converts this into a tensor of shape (num_frames, num_joints * 3).

NOTE: These models are provided using PyTorch for illustrative purposes. Feel free
to swap out the framework (e.g. Keras or TensorFlow) or adjust the
architecture details as needed.
"""

from typing import List, Tuple
import json
import numpy as np

try:
    import torch
    import torch.nn as nn
except ImportError:
    # If PyTorch is not available, define dummy placeholders. You can replace
    # these with another deep learning library of your choice.
    torch = None  # type: ignore
    nn = None  # type: ignore


def load_animation_json(path: str) -> Tuple[np.ndarray, List[float], List[str]]:
    """
    Parse the exported animation JSON file.

    Parameters
    ----------
    path : str
        Path to the JSON file exported by AnimationDataRecorder.

    Returns
    -------
    data : np.ndarray
        A 2D array of shape (num_frames, num_features) containing the flattened
        joint positions. The joint order is consistent across frames.
    times : List[float]
        A list of timestamps corresponding to each frame.
    joint_names : List[str]
        The names of joints included in the data, in the order they appear in
        the flattened array.
    """
    with open(path, 'r', encoding='utf-8') as f:
        obj = json.load(f)

    frames = obj.get("frames", [])
    if not frames:
        raise ValueError("No frames found in the JSON file. Check the recording settings.")

    # Extract a consistent order of joint names from the first frame
    first_frame = frames[0]
    joint_names = list(first_frame["positions"].keys())

    times = []
    data_rows = []
    for frame in frames:
        times.append(frame["time"])
        pos = frame["positions"]
        row = []
        for joint in joint_names:
            p = pos[joint]
            # Flatten x, y, z into separate columns
            row.extend([p["x"], p["y"], p["z"]])
        data_rows.append(row)

    data = np.array(data_rows, dtype=np.float32)
    return data, times, joint_names


__all__ = [
    "load_animation_json",
    "build_mlp",
    "build_cnn",
]