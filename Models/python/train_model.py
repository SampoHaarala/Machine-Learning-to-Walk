"""
train_model.py
================

This script trains a simple neural network to predict the next pose of a
humanoid from a sequence of recorded joint rotations.  It supports both
multi‑layer perceptrons (MLP) for frame‑to‑frame prediction and a small
1D convolutional network (CNN) for short temporal windows.  The script
reads one or more JSON files generated by a Unity ``AnimationDataRecorder``
component, constructs supervised training pairs from the raw rotations
and fits the chosen model using mean squared error loss.

The resulting weights are saved to disk as a ``.pt`` file which can be
served at runtime by ``model_server.py``.  When training with a CNN the
model learns to map a window of past frames to the next frame (e.g.
8‑frame history → next pose), whereas the MLP simply maps the current
frame to the next.

Usage
-----

::

    python train_model.py \
        --jsons path/to/clip1.json path/to/clip2.json \
        --model mlp --hidden 256 128 \
        --epochs 50 --out trained_mlp.pt

Arguments
~~~~~~~~~

``--jsons``
    One or more JSON files produced by ``AnimationDataRecorder``.

``--model``
    Either ``mlp`` (default) or ``cnn``.  Determines network type.

``--hidden``
    For MLP, an optional list of integers specifying the sizes of the
    hidden layers.  If omitted a default of [128,64] is used.

``--seq-len``
    For CNN, the temporal window length (default 8).  Must be ≥2.

``--epochs``
    Number of training epochs (default 20).

``--lr``
    Learning rate (default 1e‑3).

``--out``
    Output file name for the saved model weights.  Required.

``--device``
    Optional device override (e.g. ``cuda`` or ``cpu``).  By default the
    script selects CUDA if available.

Notes
~~~~~

* The JSON files must contain a list of frames under the key ``"frames"``,
  and each frame must have a ``"rotations"`` list of equal length.  The
  dimension ``D`` of this list becomes both the input and output size of
  the network.

* Rotations are assumed to be in degrees.  The script converts them to
  radians internally for better numerical stability.  If you wish to
  work directly in degrees simply remove the call to ``np.deg2rad``.

* No normalisation is applied beyond the radian conversion.  If your
  dataset exhibits large scale differences between joints you may wish
  to normalise the inputs and outputs yourself (e.g. z‑score).  See
  ``data_processing.make_loaders_mlp`` for an example.
"""

from __future__ import annotations

import json, glob, argparse, os
from pathlib import Path
from typing import List, Tuple, Optional

import numpy as np
import torch

from mlp_model_classification import build_mlp, train_mlp
from cnn_model_classification import build_cnn, train_cnn


def load_features_from_json(path: str) -> np.ndarray:
    """Load the rotation matrix from a single recorder JSON file.

    The file is expected to have the structure::

        { "frames": [ { "time": 0.0, "rotations": [r0, r1, ...] }, ... ] }

    Returns
    -------
    np.ndarray
        Array of shape (T, D) where ``T`` is the number of frames and
        ``D`` is the length of the rotations array.  The values are
        converted from degrees to radians.
    """
    with open(path, "r", encoding="utf-8") as f:
        obj = json.load(f)
    frames = obj.get("frames") or obj  # support bare list for convenience
    if not isinstance(frames, list) or len(frames) == 0:
        raise ValueError(f"No frames found in {path}")
    rot_lists = [fr["rotations"] for fr in frames]
    feats = np.array(rot_lists, dtype=np.float32)
    # Convert degrees to radians to avoid wraparound at 360°
    feats = np.deg2rad(feats)
    return feats


def make_xy_mlp(feats: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    """Construct (X,y) pairs for a one‑step MLP.

    Parameters
    ----------
    feats : np.ndarray
        Array of shape (T, D) containing features.

    Returns
    -------
    X : np.ndarray
        Shape (T-1, D).  Each row is frame ``t``.
    y : np.ndarray
        Shape (T-1, D).  Each row is frame ``t+1``.
    """
    return feats[:-1].astype(np.float32), feats[1:].astype(np.float32)


def make_xy_cnn(feats: np.ndarray, seq_len: int) -> Tuple[np.ndarray, np.ndarray]:
    """Construct (X,y) pairs for a temporal CNN.

    Produces overlapping windows of length ``seq_len`` across the time axis.

    Parameters
    ----------
    feats : np.ndarray
        (T, D) array of features.
    seq_len : int
        Length of the input window.  Must be ≥2.

    Returns
    -------
    X : np.ndarray
        (N, D, L) array where ``N = T - seq_len`` and ``L = seq_len``.  The
        channel dimension comes first as required by PyTorch Conv1d.
    y : np.ndarray
        (N, D) array of targets corresponding to the next frame after
        each window.
    """
    T, D = feats.shape
    if seq_len < 1 or T <= seq_len:
        raise ValueError(f"seq_len must be at least 1 and less than the number of frames (got T={T}, L={seq_len})")
    Xs: List[np.ndarray] = []
    Ys: List[np.ndarray] = []
    for s in range(0, T - seq_len):
        e = s + seq_len
        Xs.append(feats[s:e].T)  # (D,L)
        Ys.append(feats[e])      # (D,)
    X = np.stack(Xs, 0).astype(np.float32)
    y = np.stack(Ys, 0).astype(np.float32)
    return X, y

def parse_hidden(s: str):
    return [int(x) for x in s.split(",")] if s else []


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Train an MLP or CNN on recorded rotation data.")
    parser.add_argument("--data_glob", required=True, default="*.json", help="One or more JSON files with recorded rotations.")
    parser.add_argument("--model", choices=["mlp", "cnn"], default="mlp", help="Type of network to train.")
    parser.add_argument("--hidden", type=str, default="256,128", help="Hidden layer sizes for the MLP.")
    parser.add_argument("--seq-len", type=int, default=8, help="Input window length for CNN (>=2).")
    parser.add_argument("--epochs", type=int, default=10000, help="Number of training epochs.")
    parser.add_argument("--lr", type=float, default=1e-3, help="Learning rate.")
    parser.add_argument("--weight-decay", type=float, default=0.0, help="L2 weight decay.")
    parser.add_argument("--out", required=True, help="Path to save the trained model (.pt).")
    parser.add_argument("--device", default=None, help="Device to train on (e.g. cuda or cpu).")
    return parser.parse_args()


def main() -> None:
    args = parse_args()
    
    # Load and concatenate all recordings
    all_feats: List[np.ndarray] = []
    for path in sorted(glob.glob(args.data_glob)):
        feats = load_features_from_json(path)
        all_feats.append(feats)
    feats_concat = np.concatenate(all_feats, axis=0)

    # Determine dimensionality
    D = feats_concat.shape[1]
    if args.model == "mlp":
        X, y = make_xy_mlp(feats_concat)
        # Convert to PyTorch tensors and wrap in DataLoader
        import torch.utils.data as data
        ds = data.TensorDataset(torch.from_numpy(X), torch.from_numpy(y))
        loader = data.DataLoader(ds, batch_size=256, shuffle=True)
        model = build_mlp(input_dim=D, output_dim=1, hidden_layers=parse_hidden(args.hidden))
        # Train
        train_mlp(model, loader, val_loader=None, epochs=args.epochs, lr=args.lr, weight_decay=args.weight_decay)
    else:
        # CNN: build sliding windows
        X, y = make_xy_cnn(feats_concat, seq_len=args.seq_len)
        import torch.utils.data as data
        ds = data.TensorDataset(torch.from_numpy(X), torch.from_numpy(y))
        loader = data.DataLoader(ds, batch_size=128, shuffle=True)
        model = build_cnn(input_channels=D, output_dim=1)
        train_cnn(model, loader, val_loader=None, epochs=args.epochs, lr=args.lr, weight_decay=args.weight_decay)
    # Save model
    os.makedirs(os.path.dirname(args.out), exist_ok=True)
    torch.save(model.state_dict(), args.out)
    print(f"Model saved to {args.out}")


if __name__ == "__main__":
    main()